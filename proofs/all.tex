\documentclass[12pt]{article}

\usepackage{bbm,fullpage}
\usepackage{amsmath}
\usepackage{alltt, amssymb, amsthm}
\usepackage{algorithm, pseudocode}
\usepackage{mathrsfs}
\usepackage[colorlinks=true,linkcolor=cyan]{hyperref}
\usepackage{bm}


\def\C {\ensuremath{\mathbb{C}}}
\def\Q {\ensuremath{\mathbb{Q}}}
\def\N {\ensuremath{\mathbb{N}}}
\def\R {\ensuremath{\mathbb{R}}}
\def\Z {\ensuremath{\mathbb{Z}}}
\def\F {\ensuremath{\mathbb{F}}}
\def\H {\ensuremath{\mathbb{H}}}
\def\K {\ensuremath{\mathbb{K}}}
\def\Kbar {{\ensuremath{\overline{\mathbb{K}}}}}
\def\A {\ensuremath{\mathbb{A}}}
\def\D {\ensuremath{D}}
\def\m {\ensuremath{\mathfrak{m}}}
\def\todo#1{(\textbf{todo:} #1)}

\def\scrM {\ensuremath{\mathscr{M}}}
\def\calL {\ensuremath{\mathcal{L}}}
\def\scrP {\ensuremath{\mathscr{P}}}
\def\scrS {\ensuremath{\mathscr{S}}}
\def\ann {\ensuremath{\mathrm{ann}}}
\def\rk {\ensuremath{\mathrm{rk}}}

\DeclareBoldMathCommand{\bell}{\ell}
\DeclareBoldMathCommand{\bu}{u}
\DeclareBoldMathCommand{\bv}{v}
\DeclareBoldMathCommand{\bX}{X}
\DeclareBoldMathCommand{\bx}{x}
\DeclareBoldMathCommand{\balpha}{\alpha}
\DeclareBoldMathCommand{\bbeta}{\beta}

\newtheorem*{Example}{Example}
\newtheorem{Coro}{Corollary}
\newtheorem{Def}{Definition}
\newtheorem{Theo}{Theorem}
\newtheorem{Prop}{Proposition}
\newtheorem{Lemma}{Lemma}

\title{Some generating series formulas}
\date{}

\begin{document}

\maketitle

\subsubsection{Overview.}

In what follows, $\K$ is a field.  Let $I$ be an ideal in
$\K[X_1,\dots,X_n]$ and $Q=\K[X_1,\dots,X_n]/I$ be the associated
residue class ring. Suppose that $V=V(I)$ has dimension zero, and
write it as $V=\{\balpha_1,\dots,\balpha_d\},$ with all $\balpha_i$'s
in $\Kbar^n$, and $\balpha_i=(\alpha_{i,1},\dots,\alpha_{i,n})$ for
all $i$.  We also let $\D$ be the dimension of $Q$, so that $d \le
\D$, and {\em we assume that ${\rm char}(\K)$ is greater than $D$}. In
this section, we recall and generalize results from the appendix
of~\cite{BoSaSc03}, with the objective of computing a zero-dimensional
parametrization of $V$.

The main novelty in our approach is to avoid generic coordinates as
much as possible. The algorithm will decompose $V$ into two parts: for
the first part, we will be able to use $X_1$ as a separating element;
the remaining points will be dealt with using a random linear
form. Throughout, we rely only the following operations: evaluations
of linear forms on successive powers of a given element in $Q$, say
$1,t,t^2,\dots$, and elementary operations on univariate polynomials.

The main algorithm is as follows. For the moment, we can only describe
its main structure; the details of the subroutines are given in the
next paragraphs.

\begin{algorithm}[H]
 \caption{$\mathsf{Parametrization}(\ell,t)$} {\bf
   Intput:} \vspace{-0.5em}
 \begin{itemize}\setlength\itemsep{0em}
 \item a linear form $\ell$ over $Q$
 \item $t=t_1 X_1 + \cdots + t_n X_n$
 \end{itemize}
 {\bf Output:} \vspace{-0.5em}
 \begin{itemize}\setlength\itemsep{0em}
 \item polynomials $(P,(V_1,\dots,V_n))$
 \end{itemize}
 \begin{enumerate}
 \item let $(F,(G_1,\dots,G_n),X_1)=\mathsf{ParametrizationX}_1(\ell)$
 \item let $\ell'=\mathsf{Update}(\ell,F,t)$
 \item let $(Q,(W_1,\dots,W_n),t)=\mathsf{ParametrizationGeneric}(\ell',t)$
 \item let $(F^*,(G^*_1,\dots,G^*_n),t)=\mathsf{ChangeCoordinate}(F,(G_1,\dots,G_n),t)$
 \item let  $(P,(V_1,\dots,V_n))=\mathsf{Union}(F^*,(G^*_1,\dots,G^*_n),\, Q,(W_1,\dots,W_n))$
 \item \textbf{return} $(P,(V_1,\dots,V_n),t)$
 \end{enumerate}
\end{algorithm}

The call to $\mathsf{ParametrizationX}_1(\ell)$ computes a
zero-dimensional parametrization of a subset $V'$ of $V$ for which
$X_1$ is a separating element, using values of the form
$(\ell(X_1^s))_{s \ge 0}$. We then modify $\ell$ (which in effect
removes from $V$ the points we just found) and apply
$\mathsf{ParametrizationGeneric}(\ell',t)$, to obtain a
zero-dimensional parametrization of $V''=V-V'$ using values of the form
$(\ell'(t^s))_{s \ge 0}$. The last two steps involve changing
coordinates in $(F,(G_1,\dots,G_n)$ (to use $t$ as a separating
variable instead), and performing the union of the two components $V'$
and $V''$.

\subsubsection{Basic facts on linearly recurrent sequences.} Consider a sequence $(\ell_s)_{s \ge 0} \in \K^\N$
and the associated generating series $S=\sum_{s \ge 0} \ell_s T^s \in
\K[[T]]$. The sequence $(\ell_s)_{s \ge 0}$ is {\rm linearly recurrent} if and
only if its generating series is {\em rational} that is, if there
exist polynomials $A,B$ in $\K[T]$ such that $S=A/B$; these
polynomials are unique if we assume $\gcd(A,B)=1$ and $B(0)=1$. 

We say that a degree $m$ polynomial $P\in\K[T]$ {\em cancels} a
sequence $(\ell_s)_{s \ge 0}$ if $p_0 \ell_s + \cdots + p_m
\ell_{s+m}=0$ for all $s \ge 0$, where $p_0,\dots,p_m$ are the
coefficients of $P$; this is equivalent to ${\rm rev}(P) S$ being
polynomial of degree less than $m$, with $S=\sum_{i \ge 0} \ell_s T^s$
and ${\rm rev}(P)=T^m P(1/T)$. The {\em minimal polynomial} of
sequence $(\ell_s)_{s \ge 0}$ is the monic polynomial of lowest degree
that cancels this sequence.

Given $A$ and $B$ as above, we define $\tilde B =
T^{\max(\deg(A)+1,\deg(B))}B(1/T)$.  By construction, $\tilde B$ lies
in $\K[T]$, and one can check that it is the minimal polynomial of
sequence $(\ell_s)_{s \ge 0}$.

The sequences we consider below are of the form $(\ell(t^s))_{s \ge
  0}$, for $\ell$ a $\K$-linear form $Q \to \K$ and $t$ in $Q$. For such
sequences, the following standard result will be useful.
\begin{Lemma}\label{lemma:minpoly}
  Let $t$ be in $Q$ and let $M \in \K[T]$ be its minimal
  polynomial. For a generic choice of $\ell$ in ${\rm hom}_\K(Q,\K)$,
  $M$ is the minimal polynomial of the sequence $(\ell(t^s))_{s \ge
    0}$.
\end{Lemma}





\subsubsection{Structure of the dual.}
For $i$ in $\{1,\dots,d\}$, let $Q_i$ be the local algebra at
$\balpha_i$, that is $Q_i=\Kbar[X_1,\dots,X_n]/I_i$, with $I_i$ the
$\m_{\balpha_i}$-primary component of $I$. By the Chinese Remainder
Theorem, $Q\otimes_\K \Kbar=\Kbar[X_1,\dots,X_n]/I$ is isomorphic to
the direct product $Q_1\times \cdots \times Q_d$.  We let $N_i$ be the
{\em nil-index} of $Q_i$, that is, the maximal integer $N$ such that
$\m_{\alpha_i}^N$ is not contained in $I_i$; for instance, $N_i=0$ if
and only if $Q_i$ is a field, if and only if $\balpha_i$ is a
non-singular root of $I$. We also let
$\D_i=\dim_\Kbar(Q_i)$, so that we have $D_i \ge N_i$ and $\D=\D_1 + \cdots + \D_d$.

Fix $i$ in $1,\dots,d$.  There exists a basis of the dual ${\rm
  hom}_\Kbar(Q_i,\Kbar)$ consisting of linear forms
$(\lambda_{i,j})_{1\le j \le \D_i}$ of the form
$$\lambda_{i,j}: f \mapsto (\Lambda_{i,j}(f))(\balpha_i),$$
where $\Lambda_{i,j}$ is the operator
$$f \mapsto \Lambda_{i,j}(f) = \sum_{\mu=(\mu_1,\dots,\mu_n) \in
  S_{i,j}} c_{i,j,\mu} \frac{ \partial^{\mu_1 + \cdots + \mu_n} f}
{\partial X_1^{\mu_1} \cdots \partial X_n^{\mu_n}},$$ for some finite
subset $S_{i,j}$ of $\N^n$ and non-zero constants $c_{i,j,\mu}$ in
$\Kbar$. 
%% Let $w_{i,j}$ be the maximum of all $|\mu|$ for $\mu$ in
%% $S_{i,j}$, with $|\mu| = \mu_1 +\cdots + \mu_n $.
%% By~\cite[Lemma~3.3]{Mourrain97}, we have that $\max_j w_{i,j} =N_i$
%% for all $i$.
For instance, when $\balpha_i$ is non-singular, we have $D_i=1$, so
there is only one function $\lambda_{i,j}$, namely $\lambda_{i,1}$, we
write it $\lambda_{i,1}(f) = f(\balpha_i)$.

More generally, we can always take $\lambda_{i,1}$ of the form
$\lambda_{i,1}(f) = f(\balpha_i)$; for $j>1$, we can then also assume
that $S_{i,j}$ does not contain $\mu=(0,\dots,0)$ (that is, all terms
in $\Lambda_{i,j}$ have order $1$ or more). Thus, introducing new
variables $(U_{i,j})_{j =1,\dots,D_i}$, we deduce the existence of
non-zero homogeneous linear forms $P_{i,\mu}$ in
$(U_{i,j})_{j=1,\dots,D_i}$ such that for any $\lambda$ in ${\rm
  hom}_\Kbar(Q_i,\Kbar)$, there exist $\bu_i=(u_{i,j}) \in
\Kbar{}^{D_i}$ such that we have
\begin{align}\label{ell_param}
\lambda: f \mapsto \lambda(f)
  &= \sum_{j=1}^{D_i} u_{i,j} \lambda_{i,j}(f)\nonumber\\
  &= \sum_{j=1}^{D_i} u_{i,j} \big(\Lambda_{i,j}(f)\big)(\balpha_i)\nonumber\\
  &= \sum_{j=1}^{D_i} u_{i,j}
 \sum_{\mu=(\mu_1,\dots,\mu_n) \in
  S_{i,j}} c_{i,j,\mu} \frac{ \partial^{\mu_1 + \cdots + \mu_n} f}
{\partial X_1^{\mu_1} \cdots \partial X_n^{\mu_n}}(\balpha_i)\nonumber\\
&= \sum_{\mu=(\mu_1,\dots,\mu_n) \in S_i} P_{i,\mu}(\bu_i)
 \frac{ \partial^{\mu_1 + \cdots + \mu_n} f}
{\partial X_1^{\mu_1} \cdots \partial X_n^{\mu_n}}(\balpha_i),
\end{align}
 where $S_i$ is  the union of $S_{i,1},\dots,S_{i,D_i}$,
 with in particular $P_{i,(0,\dots,0)}=u_{i,1}$ and where $P_{i,\mu}$
 depends only on $(u_{i,j})_{j =2,\dots,D_i}$ for all $\mu$ in $S_i$,
 $\mu \ne (0,\dots,0)$. Explicily, we can write $P_{i,\mu}=\sum_{j\in
   \{1,\dots,D_i\} \text{~such that~} \mu \in S_{i,j}} c_{i,j,\mu}
 U_{i,j}$.

Fix $\lambda$ non-zero in ${\rm hom}_\Kbar(Q_i,\Kbar)$. We can then
define its {\em order} $w$ and {\em symbol} $\pi$. The former is
the maximum of all $|\mu|=\mu_1+\cdots+\mu_n$ for
$\mu=(\mu_1,\dots,\mu_n)$ in $S_i$ such that $P_{i,\mu}(\bu_i)$ is
non-zero; by~\cite[Lemma~3.3]{Mourrain97} we have $w \le
N_i-1$. Then, we let
$$\pi =\sum_{\mu \in S_i,\ |\mu|=w}P_{i,\mu}(\bu_i) X_1^{\mu_1} \cdots
X_n^{\mu_n}$$ be the {\em symbol} of $\lambda$; by construction,
this is a non-zero polynomial. In the following paragraphs, we will
need the next easy lemma.

\begin{Lemma}\label{lemma:symbol0}
  Fix $i$ in $\{1,\dots,d\}$. For a generic choice of $\lambda$ in ${\rm
  hom}_\Kbar(Q_i,\Kbar)$, and of $t_1,\dots,t_n$ in $\Kbar{}^n$,
  $\pi_i(t_1,\dots,t_n)$ is non-zero.
\end{Lemma}
\begin{proof}
  Let $\Omega$ be the maximum of all $|\mu|=\mu_1+\cdots+\mu_n$ for
  $\mu=(\mu_1,\dots,\mu_n)$ in $S_i$, and define 
  $$\Pi =\sum_{\mu \in S_i,\ |\mu|=\Omega}P_{i,\mu} X_1^{\mu_1} \cdots
  X_n^{\mu_n} \in \Kbar[U_{i,1},\dots,U_{i,D_i},X_1,\dots,X_n];$$ this
  is by construction a non-zero polynomial.  Thus, for a generic
  choice of $\bu_i=(u_{i,1},\dots,u_{i,D_i})$, that define a linear form
  $\lambda$ in ${\rm hom}_\Kbar(Q_i,\Kbar)$ as in~\eqref{ell_param},
  and of $t_1,\dots,t_n$ in $\Kbar{}^n$, the value
  $\Pi(u_{i,1},\dots,u_{i,D_i},t_1,\dots,t_n)$ is non-zero. As a
  result, the symbol of such a linear form $\lambda$ is $\pi =\sum_{\mu \in
    S_i,\ |\mu|=\Omega}P_{i,\mu}(\bu_i) X_1^{\mu_1} \cdots X_n^{\mu_n},$
  and $\pi(t_1,\dots,t_n)$ is then non-zero.
\end{proof}



Finally, we say a word about global objects.  Fix a linear form $\ell:
Q \to \K$. By the Chinese Remainder Theorem, there exist unique
$\ell_1,\dots,\ell_d$, with $\ell_i$ in ${\rm hom}_\Kbar(Q_i,\Kbar)$
for all $i$, such that the extension $\ell_\Kbar: Q\otimes_\K \Kbar
\to \Kbar$ decomposes as $\ell_\Kbar = \ell_1 + \cdots + \ell_d$. We
call {\em support} of $\ell$ the subset $\mathfrak{S}$ of
$\{1,\dots,d\}$ such that $\ell_i$ is non-zero exactly for $i$ in
$\mathfrak{S}$.  As a consequence, for all $f$ in $Q$, we have
\begin{align}\label{eq:fui}
\ell(f) &= \ell_1(f) + \cdots + \ell_d(f)\nonumber\\
&=  \sum_{i \in \mathfrak{S}} \ell_i(f).
\end{align}
For $i$ in $\mathfrak{S}$, we denote by $w_i$ and $\pi_i$ respectively
the order and the symbol of $\ell_i$. For such a subset
$\mathfrak{S}$, we also write $Q_\mathfrak{S}=\prod_{i \in
  \mathfrak{S}} Q_i$ and $V_\mathfrak{S}=\cup_{i \in \mathfrak{S}}
\{\balpha_i\}$.


\subsubsection{A fundamental formula.}  The following lemma 
gives an explicit form for a generating series of the form $\sum_{\ell
  \ge 0} \ell(v t^i)T^\ell$, for a linear form $\ell:Q \to \K$. A
slightly less precise version of it is in~\cite{BoSaSc03}.

\begin{Lemma}\label{lemma:formula}
  Let $\ell$ be in ${\rm hom}_\K(Q,\K)$, with support $\mathfrak{S}$,
  and let $\{\pi_i \mid i \in \mathfrak{S}\}$ and $\{w_i \mid i \in
  \mathfrak{S}\}$ be as above.

  Let $t=t_1 X_1 + \cdots +t_n X_n$, for some $t_1,\dots,t_n$ in $\K$
  and let $v$ be in $\K[X_1,\dots,X_n]$. Then, we have the equality
  \begin{align}\label{eq:sumgenseries}
  \sum_{s \ge 0} \ell(v t^s)T^s =
\sum_{i \in \mathfrak{S}} \frac{
  v(\balpha_i)\, w_i!\, \pi_{i}(t_1,\dots,t_n)
  T^{w_i} + (1-t(\balpha_i)    T)A_{v,i}}
  {(1-t(\balpha_i) T)^{w_{i}+1}},    
  \end{align}
 for some polynomials $\{A_{v,i} \in \Kbar[T] \mid i \in \mathfrak{S}\}$ (that
 depend on the choice of $v$), with $A_{v,i}$ of degree less than $w_i$ for all $i$ in
 $\mathfrak{S}$.
\end{Lemma}
\begin{proof}
  Take $v$ and $t$ as above. Consider first
  an operator of the form $f \mapsto \frac{ \partial^{|\mu|}  f}
  {\partial X_1^{\mu_1} \cdots \partial X_n^{\mu_n}}$, where 
we write $|\mu|=\mu_1+\cdots+\mu_n$. Then, we have
  the following generating series identities, with coefficients in 
  $\K(X_1,\dots,X_n)$:
\begin{align*}
\sum_{s \ge 0} 
\frac{ \partial^{|\mu|} ( v t^s )} {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}
 T^s 
&=  \sum_{s \ge 0} 
\frac{ \partial^{|\mu|} (v t^s T^s)} {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}\\
&=  
\frac{ \partial^{|\mu|} } {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}
 \left (\sum_{s \ge 0} v t^s T^s\right ) \\
&= \frac{ \partial^{|\mu|} } {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}
 \left (\frac v{1-tT} \right ) \\
&= v\, |\mu|!\, \prod_{1 \le k \le n} 
\left (\frac{ \partial t} {\partial X_k} \right)^{\mu_k}
\frac {T^{|\mu|}}{(1-t T)^{|\mu|+1}} + \frac{P_{|\mu|}(\bX,T)}{(1-t T)^{|\mu|}} + \cdots + \frac{P_{1}(\bX,T)}{(1-t T)}\\
&= v\, |\mu|!\, \prod_{1 \le k \le n} 
t_k^{\mu_k}
\frac {T^{|\mu|}}{(1-t T)^{|\mu|+1}} + \frac{P(\bX,T)}{(1-t T)^{|\mu|}},
\end{align*}
for some polynomials $P_1,\dots,P_{|\mu|},P$ in $\K[\bX,T]$ that
depend on the choices of $\mu$, $v$ and $t$, with $\deg(P_i,T) < i$
for all $i$ and thus $\deg(P,T) < |\mu|$.

Take now a linear combination of such operators, such as 
$f \mapsto \sum_{\mu \in R} c_\mu \frac{ \partial^{|\mu|}  f } {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}$. The corresponding generating series
becomes
\begin{align*}
\sum_{s \ge 0} 
\sum_{\mu \in R} c_\mu \frac{ \partial^{|\mu|} ( v t^s )} {\partial X_1^{\mu_1} \cdots
  \partial X_n^{\mu_n}}
 T^s 
&=
v\,\sum_{\mu \in R} c_\mu
 |\mu|!\, \prod_{1 \le k \le n} 
t_k^{\mu_k}
\frac {T^{|\mu|}}{(1-t T)^{|\mu|+1}} +\sum_{\mu \in R} \frac{P_\mu(\bX,T)}{(1-t T)^{|\mu|}},
\end{align*}
where each $P_\mu$ has degree less than $|\mu|$ in $T$.
Let $w$ be the maximum of all $|\mu|$ for $\mu$ in $R$. We can rewrite 
the above as
\begin{align*}
v\, w! 
\sum_{\mu \in R, |\mu|=w} c_\mu
\, \prod_{1 \le k \le n} 
t_k^{\mu_k}
\frac {T^{w}}{(1-t T)^{w+1}}
 + \frac{A(\bX,T)}{(1-t T)^{w}},
\end{align*}
for some polynomial $A$ of degre less than $w$ in $T$. If we let 
$\pi =\sum_{\mu \in R,\ |\mu|=w} c_{\mu} X_1^{\mu_1} \cdots
  X_n^{\mu_n}$, this becomes
\begin{align*}
\sum_{s \ge 0} 
\sum_{\mu \in R} c_\mu \frac{ \partial^{|\mu|} ( v t^s )} { X_1^{\mu_1} \cdots
 X_n^{\mu_n}}
 T^s 
&=
v\, w! \,  \pi(t_1,\dots,t_n)
\frac {T^{w}}{(1-t T)^{w+1}}
 + \frac{A(\bX,T)}{(1-t T)^{w}}.
\end{align*}
Applying this formula to the sum in~\eqref{eq:fui}, we obtain the
claim in the lemma.
\end{proof}

\noindent 
The most useful consequence of the previous lemma is the following
interpolation formula, where we fix a subset $\mathfrak{S}$ of 
$\{1,\dots,d\}$. The mapping $t:V_\mathfrak{S} \to \Kbar$
defined by $\balpha_i \mapsto t(\balpha_{i})$ plays a special role in
the formula in the lemma; this leads us to the following definitions.
\begin{itemize}
\item We consider $\ell$ and $t$ as in Lemma~\ref{lemma:formula}, such
  that $\ell$ has support $\mathfrak{S}$.
\item $\mathfrak{T}$ is the subset of $\mathfrak{S}$ consisting of
  all indices $i$ such that 
  \begin{itemize}
  \item $\pi_i(t_1,\dots,t_n)$ is non-zero;
  \item $t(\balpha_{i'}) \ne t(\balpha_i)$ for $i' \ne i$ in $\mathfrak{S}$.
  \end{itemize}
\item $\{r_1,\dots,r_c\}$ are the pairwise distinct values taken by $t$ on
  $V_\mathfrak{S}$, for some $c \le |\mathfrak{S}|$.
\item $\mathfrak{t}$ is the set of all indices $j$ in
  $\{1,\dots,c\}$ such that
  \begin{itemize}
  \item the fiber $t^{-1}(r_j) \subset V_{\mathfrak{S}}$ contains a single
    point, written $\balpha_{\sigma_j}$;
  \item the point $\balpha_{\sigma_j}$ is in $\mathfrak{T}$
    (equivalently,  $\pi_{\sigma_j}(t_1,\dots,t_n)$ is non-zero).
  \end{itemize}
  Remark that $j \mapsto \sigma_j$ induces a one-to-one correspondence
  between  $\mathfrak{t}$ and  $\mathfrak{T}$.
\end{itemize}

\begin{Lemma}
  Let $\ell$, $t$ and all other notation be as above. Let further
  $M$ be the minimal polynomial of $t$ in $Q_\mathfrak{S}$, let
  $\delta$ be its degree and let $B=T^\delta M(1/T)$. Suppose that 
  $M$ is also the minimal polynomial of the sequence $(\ell(t^s))_{s \ge 0}$.
  Then, the following holds:
  \begin{itemize}
  \item for $v$ in $\K[X_1,\dots,X_n]$, the power series $C_v =
    \Big(\sum_{s \ge 0} \ell(v t^s)T^s\Big)B$ is actually a polynomial
    of degree less than $\delta$;
  \item there exist non-zero constants $\{c_j \mid j \in
    \mathfrak{t}\}$  such that for $v$ in
    $\K[X_1,\dots,X_n]$, the polynomial $\tilde C_v = T^{\delta-1}
    C_v(1/T)$ satisfies
    $$\tilde C_v(r_j) = c_{j} v(\balpha_{\sigma_j}) \quad \text{for all $j$ in $\mathfrak{t}$.}$$
  \end{itemize}
\end{Lemma}
\begin{proof}
For $j=1,\dots,c$, we write $T_j$ for the set of all indices $i$ in
$\mathfrak{S}$ such that $t(\balpha_{i})=r_j$; the sets
$T_1,\dots,T_c$ form a partition of $\mathfrak{S}$. When $T_j$ has
cardinality~$1$, we thus have $T_j=\{\sigma_j\}$.

Take an arbitrary $v$ in $\K[X_1,\dots,X_n]$ and let us
collect terms in~\eqref{eq:sumgenseries} as
\begin{align*}
  \sum_{s \ge 0} \ell(v t^s)T^s =&
  \sum_{j \in \{1,\dots,c\}}
  \sum_{i \in T_j} \frac{
v(\balpha_{i})   w_{i}!\, \pi_{i}(t_1,\dots,t_n)
    T^{w_{i}} + (1-r_{j}  T)A_{v,i}}
      {(1-r_{j} T)^{w_{i}+1}}\\
 =&
  \sum_{j \in \mathfrak{s}}
\frac{
v(\balpha_{\sigma_{j}})  w_{\sigma_j}!\, \pi_{\sigma_j}(t_1,\dots,t_n)
    T^{w_{\sigma_j}} + (1-r_{j}  T)A_{v,\sigma_j} }
      {(1-r_{j} T)^{w_{\sigma_j}+1}}\\
&+
  \sum_{j \in \{1,\dots,c\}-\mathfrak{s}}
 \frac{   \sum_{i \in T_j} \Big( \big[
v(\balpha_{i})   w_{i}!\, \pi_{i}(t_1,\dots,t_n)
    T^{w_{i}} + (1-r_{j}  T)A_{v,i} \big ]
(1-r_{j} T)^{y_j-(w_i+1)}\Big)}
      {(1-r_{j} T)^{y_j}},
\end{align*}
where $y_j$ is the maximum of all $w_i$ for $i$ in $T_j$.  Remark that
for $v=1$, our condition that $\pi_i$ is non-zero for $i$ in
$\mathfrak{T}$ implies that in the second line, together with our
assumption on the characteristic of $\K$, imply that all terms in the
first sum are non-zero and in reduced form.  

After simplyfing terms in the second sum, we can rewrite the
expression above as
\begin{align*}
  \sum_{s \ge 0} \ell(v t^s)T^s =&
  \sum_{j \in \mathfrak{t}} \frac{
v(\balpha_{\sigma_{j}})   w_{\sigma_{j}}!\, \pi_{{\sigma_{j}}}(t_1,\dots,t_n)
    T^{w_{\sigma_{j}}} + (1-r_{j}  T)A_{v,\sigma_{j}}}
      {(1-r_{j} T)^{w_{\sigma_{j}}+1}}  
+\sum_{j \in  \{1,\dots,c\}-\mathfrak{s}}
\frac{D_{v,j}}
  {(1-r_{j} T)^{z_{v,j}}},
\end{align*}
for some positive integers $\{z_{v,j} \mid j\in
\{1,\dots,c\}-\mathfrak{s}\}$ and polynomials $\{D_{v,j} \mid j\in
\{1,\dots,c\}-\mathfrak{s}\}$ such that for all $j$ in $
\{1,\dots,c\}-\mathfrak{s}$, we have $\deg(D_{v,j}) < z_{v,j}$ and
$\gcd(D_{v,j}, (1-r_{j} T))=1$; the integers $z_{v,j}$ are uniquely
determined by these conditions, except if $r_{j}=0$, in which case we
set $z_{v,j}=\deg(D_{v,j})+1$. Some of the polynomials $D_{v,j}$ may
vanish, so we let $\mathfrak{u}_v \subset \{1,\dots,c\}-\mathfrak{s}$
be the set of all $j$ for which this is not the case. 
We then arrive at our final form for this sum, namely
\begin{align}\label{eq:sumgenseries_collect1}
  \sum_{s \ge 0} \ell(v t^s)T^s =&
  \sum_{j \in \mathfrak{t}} \frac{
v(\balpha_{\sigma_{j}})   w_{\sigma_{j}}!\, \pi_{{\sigma_{j}}}(t_1,\dots,t_n)
    T^{w_{\sigma_{j}}} + (1-r_{j}  T)A_{v,\sigma_{j;}}}
      {(1-r_{j} T)^{w_{\sigma_{j}}+1}}  
+\sum_{j \in  \mathfrak{u}_v}
\frac{D_{v,j}}
  {(1-r_{j} T)^{z_{v,j}}},
\end{align}
where all terms in the second sum are non-zero and in reduced form
(and similarly for the first sum, for $v=1$).
This implies that the minimal
polynomial of the sequence $(\ell(vt^s))_{s \ge 0}$ is 
$$M_v=\prod_{j \in \mathfrak{t}} (T-r_{j})^{\zeta_j} \prod_{j
  \in \mathfrak{u}_v} (T-r_{j})^{z_{v,j}},$$
for some integers $\{\zeta_j \le w_{\sigma_{j}}+1 \mid j \in \mathfrak{t}\}$; for $v=1$, 
we actually have $\zeta_j = w_{\sigma_{j}}+1$ for all such~$j$.

Now, for $v=1$, we assume that the minimal polynomial of the sequence
$(\ell(t^s))_{s \ge 0}$ is the minimal polynomial $M$ of $t$ in
$Q_\mathfrak{S}$.  Writing $\mathfrak{u}=\mathfrak{u}_1$ and
$z_k=z_{1,k}$ for all $k$ in $\mathfrak{u}$, we can thus write it as
$$M=\prod_{j \in \mathfrak{t}} (T-r_{j})^{w_{\sigma_{j}}+1} \prod_{j
  \in \mathfrak{u}} (T-r_{j})^{z_{j}}.$$ Since it is the minimal
polynomial of $t$ in $Q_\mathfrak{S}$, it also cancels the sequence
$(\ell(v t^s))_{s \ge 0}$ for any $v$, so that for all $v$,
$\mathfrak{u}_v$ is contained in $\mathfrak{u}$ and $M_v$ divides $M$.
Remark also that the integer $\delta=\deg(M)$ is given by
$$\delta=\sum_{j \in \mathfrak{t}} (w_{\sigma_j}+1)
+\sum_{j\in\mathfrak{u}} z_{j},$$
and $B=T^{\delta}M(1/T)$ satisfies
$$B=\prod_{j \in \mathfrak{t}}(1-r_{j} T)^{w_{\sigma_j}+1} \prod_{j \in
  \mathfrak{u}}(1-r_{j} T)^{z_{j}}.$$ 

For $v$ arbitrary in $\K[X_1,\dots,X_n]$, since  $M$ cancels the sequence
$(\ell(v t^s))_{s \ge 0}$, the power series $C_v =
\big(\sum_{s \ge 0} \ell(vt^s)T^s\big)B$ defined in the statement of
the lemma is indeed a polynomial of degree less than $\delta$ (this
proves our first claim). We can then rewrite the
sum in~\eqref{eq:sumgenseries_collect1} as $ \sum_{s \ge 0} \ell(v
t^s)T^s =C_v/B$, with
\begin{align*}
  C_v=&\sum_{j \in \mathfrak{t}} \Big(\big[
    v(\balpha_{\sigma_{j}}) w_{\sigma_{j}}!\, \pi_{\sigma_{j}}(t_1,\dots,t_n)
    T^{w_{\sigma_{j}}} + (1-r_{j} T)A_{v,\sigma_{j}}\big]
  \prod_{\iota \in \mathfrak{t}-\{j\}}(1-r_{\iota} T)^{w_{\sigma_{\iota}}+1}
  \Big)\Big (\prod_{j \in \mathfrak{u}}(1-r_{j} T)^{z_{j}}\Big)\\
  &+
  \Big (\prod_{j \in \mathfrak{t}}(1-r_{j} T)^{w_{\sigma_{j}}+1} \Big)
  \sum_{j \in \mathfrak{u}_v} \Big (D_{v,j} 
  (1-r_j T)^{z_{j}-z_{v,j}}
  \prod_{\iota \in \mathfrak{u}-\{j\}}(1-r_{\iota} T)^{z_{\iota}}\Big).
\end{align*}
Since $\delta-1$ is an upper bound on the degree of $C_v$,
we can then define $\tilde C_v = T^{\delta-1}C_v(1/T)$, that is,
\begin{align*}
  \tilde  C_v=&\sum_{j \in \mathfrak{t}} \Big(\big[
    v(\balpha_{\sigma_{j}})  w_{\sigma_j}!\, \pi_{\sigma_j}(t_1,\dots,t_n)
    + (T-r_j)\tilde A_{v,\sigma_j}\big]
  \prod_{\iota \in \mathfrak{t}-\{j\}}(T-r_{\iota} )^{w_{\sigma_{\iota}}+1}
  \Big)\prod_{j \in \mathfrak{u}}(T-r_j )^{z_j}
  \\
  &+
  \Big(\prod_{j \in \mathfrak{t}}(T-r_{j} )^{w_{\sigma_j}+1}\Big)
  \sum_{j \in \mathfrak{u}_v} \Big (\tilde D_{v,j}
  (1-r_j T)^{z_{j}-z_{v,j}}
  \prod_{\iota \in \mathfrak{u}-\{j\}}(T-r_{\iota} )^{z_{\iota}}\Big),
\end{align*}
with $\tilde A_{v,\sigma_j} = T^{w_{\sigma_j}-1} A_{v,\sigma_j}(1/T) \in \Kbar[T]$
for $j$ in $\mathfrak{t}$ and
and $\tilde D_{v,j}=T^{z_{v,j}-1} D_{v,j}(1/T)$ for $j$ in $\mathfrak{u}_v$. In particular, 
for $k$ in $\mathfrak{t}$,
the value $\tilde C_v(r_k)$ is 
\begin{align*}
  \tilde C_v(r_k)&= v(\balpha_{\sigma_{k}}) w_{\sigma_k}!\, \pi_{\sigma_k}(t_1,\dots,t_n)
  \prod_{\iota \in \mathfrak{t}-\{k\}}(r_\iota-r_{k} )^{w_{\sigma_{\iota}}+1}
\prod_{j \in \mathfrak{u}}(r_j-r_{k} )^{z_{k}}\\
&= v(\balpha_{\sigma_{k}}) c_{k},
\end{align*}
with 
$$c_{k}=
 w_{\sigma_k}!\, \pi_{\sigma_k}(t_1,\dots,t_n)
\prod_{\iota \in \mathfrak{t}-\{k\}}(r_\iota-r_{k} )^{w_{\sigma_{\iota}}+1}
\prod_{j \in \mathfrak{u}}(r_j-r_{k} )^{z_{k}}$$
for $k$ in $\mathfrak{t}$. This is a non-zero constant, independent 
of $v$, which finishes the proof of the lemma.
\end{proof}

As an application, the following algorithm shows how to compute a
zero-dimensional parametrization of $V_{\mathfrak{S}}$.

\begin{algorithm}[H]
 \caption{$\mathsf{ParametrizationGeneric}(\ell,t)$}
~\\
 {\bf Input:} \vspace{-0.5em}
 \begin{itemize}\setlength\itemsep{0em}
 \item  a linear form $\ell$ over $Q_\mathfrak{S}$
 \item $t=t_1 X_1 + \cdots + t_n X_n$
 \end{itemize}
 {\bf Output:} polynomials $(P,V_1,\dots,V_n)$
 \begin{enumerate}\setlength\itemsep{0em}
 \item let $M$ be the minimal polynomial of the sequence $(\ell(t^s))_{s \ge 0}$ and let $\delta$ be its degree
 \item let $P$ be the squarefree part of $M$
 \item let $B=T^\delta M(1/T)$
 \item let $C_1 = B\big (\sum_{s < \delta} \ell(t^s)T^s\big ) \mod T^{\delta}$
 \item let $\tilde C_1 = T^{\delta -1}C_1(1/T)$
 \item \textbf{for} $i=1,\dots,n$ \textbf{do}
   \begin{enumerate}
   \item let $C_{X_i} = B\big (\sum_{s < \delta} \ell(X_i t^s)T^s\big) \mod T^{\delta}$ 
   \item let $\tilde C_{X_i} = T^{\delta -1}C_{X_i}(1/T)$
   \end{enumerate}
 \item \textbf{return} $(P,\tilde C_{X_1}/\tilde C_1 \bmod P, \dots,\tilde C_{X_n}/\tilde C_{1} \bmod P)$
 \end{enumerate}
\label{algo:para}
\end{algorithm}

\begin{Lemma}
  Suppose that $\ell$ is a generic element of ${\rm
    hom}_{\Kbar}(Q_\mathfrak{K},\Kbar)$ and that $t$ is a generic
  linear form. Then the output $((P,V_1,\dots,V_n),t)$ of
  $\mathsf{Parametrization}(\ell,t)$ is a zero-dimensional
  parametrization of $V_{\mathfrak{S}}$.
\end{Lemma}
\begin{proof}
  A generic choice of $t$ separates the points of $V_{\mathfrak{S}}$,
  and we saw in Lemma~\ref{lemma:symbol0} that for a generic choice of
  $\ell$, $\pi_i(t_1,\dots,t_n)$ vanishes for no $i$ in
  $\mathfrak{S}$.  As a result, $\mathfrak{T}=\mathfrak{S}$.  Besides,
  we recall that for a generic $\ell$ in ${\rm
    hom}_{\Kbar}(Q_\mathfrak{S},\Kbar)$, the minimal polynomials of
  $(\ell(t^s))_{s \ge 0}$ and of $t$ are the same
  (Lemma~\ref{lemma:minpoly}).

  Thus, the polynomial $M$ we compute at step 1 is indeed the minimal
  polynomial of $t$, and we can apply the previous lemma, and for 
  any root $r_j$ of $P$, and $i=1,\dots,n$, we have
  $$\frac{\tilde C_{X_i}(r_j)}{\tilde C_1(r_j)}  = \frac{c_j \alpha_{\sigma_j,i}}{c_j} = \alpha_{\sigma_j,i},$$
  so that $\tilde C_{X_i}/\tilde C_1 \bmod P$ is the $i$th polynomial in
  the zero-dimensional parametrization of $V$ corresponding to $t$.
\end{proof}

\subsubsection{Decomposition of linear forms.}

In this paragraph, we work over the whole $V$ (so
$\mathfrak{S}=\{1,\dots,d\}$).  Specializing our previous discussion
to the case $t=X_1$, we let $r_1,\dots,r_c$ be the pairwise distinct
values taken by $X_1$ on $V$, for some $c \le d$.  For
$j=1,\dots,c$, we write $T_j$ for the set of all indices $i$ in
$\{1,\dots,d\}$ such that $\alpha_{i,1}=r_j$; the sets $T_1,\dots,T_c$
form a partition of $\{1,\dots,d\}$. When $T_j$ has cardinality~$1$,
we denote it as $T_j=\{\sigma_j\}$, for some index $\sigma_j$ in
$\{1,\dots,d\}$, so that $\alpha_{\sigma_j,1}=r_j$.

For $i=1,\dots,d$, let us write $\nu_i$ for the degree of the minimal
polynomial of $X_1$ in $Q_i$; thus, this polynomial is
$(T-\alpha_{i,1})^{\nu_i}$. For $j$ in $\{1,\dots,c\}$, we define
$m_j$ as the maximum of all $\nu_i$, for $i$ in~$T_j$. As a result, the minimal
polynomial of $X_1$ in $\prod_{j \in T_j} Q_j$ is 
$(T-r_j)^{m_j}$, and the minimal polynomial of $X_1$ in $Q$ is
$M=\prod_{j \in \{1,\dots,c\}} (T-r_j)^{m_j}$.

Recall that a linear form $\ell: Q \to \Kbar$ can be written uniquely
as $\ell=\sum_{i\in \{1,\dots,d\}} \ell_i$, with $\ell_i:Q_i \to
\Kbar$; collecting terms, $\ell$ may also be written as $\ell=\sum_{j
  \in \{1,\dots,c\}} \lambda_j$, with $\lambda_j=\sum_{i \in T_j}
\ell_i$.  Given such an $\ell$, we first explain how to compute values
of the form $\lambda_j(1)$. We will do this for some values of $j$
only, namely those $j$ for which $m_j=1$.

\begin{Lemma}\label{lemma:valuelambda}
  Let $\ell$ be in ${\rm hom}_\K(Q,\K)$, let $M$ be the minimal
  polynomial of $X_1$ in $Q$, let $\delta$ be its degree and 
  let $B=T^{\delta}M(1/T)$. Then, the following holds:
  \begin{itemize}
  \item the power series $A = \Big(\sum_{s \ge 0}
    \ell(X_1^s)T^s\Big)B$ is actually a polynomial of degree less than~$\delta$;
  \item the polynomial $\tilde A = T^{\delta-1} A(1/T)$ satisfies
    $$\tilde A(r_j) = \lambda_j(1) M'(r_j) \quad \text{for all $j$ such that $m_j=1$.}$$
  \end{itemize}
\end{Lemma}
\begin{proof}
Let $\mathfrak{e}$ be the set of all indices $j$ in $\{1,\dots,c\}$
such that $m_j=1$, and let $\mathfrak{f}=\{1,\dots,c\}-\mathfrak{e}$;
this definition allows us to split the sum as
\begin{align*}
\sum_{s \ge 0} \ell(X_1^s) T^s  
&= \sum_{j \in \{1,\dots,c\}}\sum_{i\in T_j} 
\sum_{s \ge 0}\ell_i(X_1^s)T^s  \\
&=\sum_{j \in \mathfrak{e}}\sum_{i\in T_j}\sum_{s \ge 0}  \ell_i(X_1^s)T^s +
\sum_{j \in \mathfrak{f}}\sum_{i\in T_j}\sum_{s \ge 0}  \ell_i(X_1^s)T^s.
\end{align*}
Using Lemma~\ref{lemma:formula} with $t=X_1$ and $v=1$, any sum $\sum_{s \ge 0} \lambda_j(X_1^s)T^s$ 
in the second summand
can be rewritten as 
$$\frac{C_j}{(1-r_j T)^{v_j}},$$
for some integer $v_j$, and for some polynomial $C_j$ of degree less than
$v_j$. Next, take $j$ in $\mathfrak{e}$. Since $m_j=1$, $\nu_i=1$ for all $i$ in $T_j$,
 so that
each such $\ell_i$ takes the form 
$$\ell_i: f \mapsto (\Lambda_{i}(f))(\balpha_i),$$ where $\Lambda_{i}$
is a differential operator that does not involve $\partial/\partial
X_1$. Since all terms of positive order in $\Lambda_i$ involve one of
$\partial/\partial X_2,\dots,\partial/\partial X_n$, they cancel
$X_1^s$ for $s\ge 0$. Thus, $\ell_i(X_1^s)$ can be rewritten 
as $\ell_{i,1} \alpha_{i,1}^s$, for some constant $\ell_{i,1}$,
and the generating series of these terms is 
$$\frac {\ell_{i,1}}{1-\alpha_{i,1}T}=\frac {\ell_{i,1}}{1-r_j T}.$$
Remarking  that we can write $\ell_{i,1}=\ell_i(1)$,
altogether, the sum in question can be written
\begin{align*}
\sum_{s \ge 0} \ell(X_1^s) T^s  
&=\sum_{j \in \mathfrak{e}} 
\frac{ \sum_{i\in T_j}  \ell_{i}(1) }{1-r_j T}
+ \sum_{j \in \mathfrak{f}} \frac{D_j}{(1-r_j T)^{x_j}}\\
&= \sum_{j \in \mathfrak{e}} 
\frac{ \lambda_j(1) }{1-r_j T}
+ \sum_{j \in \mathfrak{f}} \frac{D_j}{(1-r_j T)^{x_j}}
\end{align*}
for some integers $\{x_j \mid j \in b\}$ such that $\deg(D_j) < x_j$
holds, and with $D_j$ and $1-r_j T$ coprime; if $r_j=0$, we take
$x_j=\deg(D_j)+1$. In particular, the minimal polynomial of
$(\ell(X_1^s))_{s\ge 0}$ is $N=\prod_{j\in \mathfrak{e}}(T-r_j)
\prod_{j \in \mathfrak{f}}(T-r_j)^{x_j}$.

On the other hand, the minimal polynomial $M$ of $X_1$ can be rewritten as $M=\prod_{j\in
  \mathfrak{e}}(T-r_j) \prod_{j \in \mathfrak{f}}(T-r_j)^{m_j}$, so
that $\delta=\sum_{j \in \mathfrak{e}} 1 + \sum_{j\in \mathfrak{f}}
m_j$ and $B=\prod_{j\in \mathfrak{e}}(1-r_j T) \prod_{j \in
  \mathfrak{f}}(1-r_j T)^{m_j}$. The minimal polynomial
of the sequence $\ell(X_1^s)$ divides $M$, so that $x_j \le m_j$ holds for all $j$ in
$\mathfrak{f}$.
As a result,  $A =\big ( \sum_{s \ge 0} \ell(X_1^s) T^s \big ) B$ is 
indeed a polynomial of degree less than $\delta$, given by
\begin{align*}
  A=&
\sum_{j \in \mathfrak{e}}
\Big(
\lambda_j(1) \prod_{\iota \in \mathfrak{e}-\{j\}}(1-r_\iota T)\Big)
\Big(\prod_{j \in \mathfrak{f}}(1-r_j T)^{m_j} \Big)\\
&+
\sum_{j\in \mathfrak{f}}
\Big(D_j (1-r_j T)^{m_j-x_j}
\prod_{\iota \in \mathfrak{f}-\{j\}}(1-r_j T)^{m_\iota}\Big)
\Big(\prod_{j\in \mathfrak{e}} (1-r_jT) \Big).
\end{align*}
The reciprocal polynomial $\tilde A=T^{\delta-1} A(1/T)$ is then
\begin{align*}
\tilde  A=&
\sum_{j \in \mathfrak{e}}
\Big(
\lambda_j(1) \prod_{\iota \in \mathfrak{e}-\{j\}}(T-r_\iota)\Big)
\Big(\prod_{j \in \mathfrak{f}}(T-r_j)^{m_j} \Big)\\
&+
\sum_{j\in \mathfrak{f}}
\Big(\tilde D_j (T-r_j)^{m_j-x_j}
\prod_{\iota \in \mathfrak{f}-\{j\}}(T-r_j)^{m_\iota}\Big)
\Big(\prod_{j\in \mathfrak{e}} (T-r_j) \Big),
\end{align*}
with $\tilde D_j = T^{x_j-1} D_j(1/T)$ for all $j$ in $\mathfrak{f}$.
This implies that $$\tilde A(r_k) =\lambda_k(1) 
\prod_{\iota \in \mathfrak{e}-\{k\}}(r_k-r_\iota)
\prod_{j \in \mathfrak{f}}(r_k-r_j)^{m_j} = \lambda_k(1) M'(r_k)$$ 
holds for all $k$ in $\mathfrak{e}$.
\end{proof}

We then show how to use this result to avoid (as much as possible)
using a generic linear form $t=t_1 X_1 + \cdots + t_n X_n$, and how to
use (say) $X_1$ instead to compute a zero-dimensional parametrization
of a subset of $V$; this is motivated by the fact that the
multiplication matrix by $X_1$ is expected to be sparser than that of
$t$ (since the matrix of $t$ is a combination of those of
$X_1,\dots,X_n$), sometimes by a substantial amount. Of course, there
is no guarantee that $X_1$ is a separating element for $V$. As a
result, we will compute a decomposition of $V$ into two components
$V'$ and $V''$; $X_1$ will be a separating element for $V'$, whereas
we will use a generic linear form to describe $V''$.

More precisely, we characterize the set $V'$ mentioned above as follows: for $i$ in
$\{1,\dots,d\}$, $\balpha_i$ is in $V'$ if and only if:
\begin{itemize}
\item for $i'$ in $\{1,\dots,d\}$, with $i'\ne i$, $\alpha_{i',1} \ne
  \alpha_{i,1}$;
\item $Q_i$ is a reduced algebra (equivalently, $I_i$ is radical).
\end{itemize}
We denote by $\mathfrak{A}\subset \{1,\dots,d\}$ the set of
corresponding indices $i$, and we let
$\mathfrak{B}=\{1,\dots,d\}-\mathfrak{a}$, so that we have
$V'=V_{\mathfrak{A}}$ and $V''=V_{\mathfrak{B}}$.  Remark that $X_1$
is a separating element for $V'$.

Correspondingly, we define $\mathfrak{a}$ as the set of all indices
$j$ in $\{1,\dots,c\}$ such that $\sigma_j$ is in $\mathfrak{A}$. In
other words, $j$ is in $\mathfrak{a}$ if and only if $T_j$ has
cardinality $1$ and $Q_{\sigma_j}$ is reduced.  The algorithm in this
paragraph will compute a zero-dimenstional parametrization of
$V_{\mathfrak{A}}$; we use the following lemma to perform this
decomposition of $V$.

\begin{Lemma}\label{lemma:acb2}
  Let $j$ be in $\{1,\dots,c\}$ such that $m_j=1$, let $\lambda$ be a
  linear form over $\prod_{i \in T_j} Q_i$ and let $t=t_2 X_2
  + \cdots + t_n X_n$. Define constants $a,b,c$ in $\Kbar$ by
  $$a=\lambda(1),\quad b=\lambda(t),\quad c=\lambda(t^2).$$
  Then, $j$ is in $\mathfrak{a}$
  if and only if, for a generic choice of $\lambda$ and $t$, $ac=b^2$.
\end{Lemma}
\begin{proof}
  The assumption that $m_j=1$ means that for all $i$ in $T_j$,
  $\nu_i=1$. The linear 
  form $\lambda$ can be uniquely written as a sum $\lambda=\sum_{i \in T_j}
  \ell_i$, where each $\ell_i$ is in ${\rm hom}_\Kbar(Q_i,\Kbar)$.
  The fact that all $\nu_i$ are equal to $1$ then implies that each $\ell_i$ takes the form 
  $$\ell_i: f \mapsto (\Lambda_{i}(f))(\balpha_i),$$
  where $\Lambda_{i}$ is a differential operator that does not 
  involve $\partial/\partial X_1$. Thus, as in~\eqref{ell_param}, we can write a general
  $\Lambda_i$ of this form as
  $$\Lambda_i: f \mapsto u_{i,1} f + \sum_{2 \le r \le n}
  P_{i,r}(u_{i,2},\dots,u_{i,D_i}) \frac{\partial}{\partial X_j} f +
  \sum_{2 \le r \le s \le n} P_{i,r,s}(u_{i,2},\dots,u_{i,D_i})
  \frac{\partial^2}{\partial X_j\partial X_k} f +
  \tilde\Lambda_i(f),$$ where all terms in $\tilde \Lambda_i$ have
  order at least $3$, $\bu_i=(u_{i,1},\dots,u_{i,D_i})$ are parameters and
  $(P_{i,r})_{2 \le r \le n}$ and $(P_{i,r,s})_{2 \le r \le s \le n}$
  are linear forms in $u_{i,2},\dots,u_{i,D_i}$.
We obtain
\begin{align*}
\Lambda_i(1)   &= u_{i,1} \\
\Lambda_i(t)   &= u_{i,1} t +\sum_{2 \le r \le n}P_{i,r}t_r \\
\Lambda_i(t^2) &= u_{i,1} t^2  +2 t \sum_{2 \le r \le n}P_{i,r}t_r   
                                                + 2\sum_{2 \le r \le s \le n} P_{i,r,s}t_rt_s,
\end{align*}
which gives
\begin{align*}
a  &= \sum_{i\in T_j}u_{i,1} \\
b  &= \sum_{i\in T_j}u_{i,1} t(\balpha_i) +\sum_{i \in T_j, 2 \le r \le n}P_{i,r}t_r \\
c &= \sum_{i\in T_j}u_{i,1} t(\balpha_i)^2  +2  \sum_{i \in T_j, 2 \le r \le n}t(\balpha_i) P_{i,r}t_r    
                                                +2 \sum_{i \in T_j, 2 \le r \le s \le n} P_{i,r,s}t_rt_s.
\end{align*}
Suppose first that $j$ is in $\mathfrak{a}$. Then, $T_j=\{\sigma_j\}$, so we 
have only one term $\Lambda_{\sigma_j}$ to consider, and $Q_{\sigma_j}$ 
is reduced, so that all coefficients $P_{\sigma_j,r}$ and
$P_{\sigma_j,r,s}$ vanish. Thus, we are left in
this case with
$$
a = u_{\sigma_j,1}, \quad
b = u_{\sigma_j,1} t(\balpha_{\sigma_j}), \quad
c = u_{\sigma_j,1} t(\balpha_{\sigma_j})^2,
$$ so that we have $ac=b^2$, for {\em any} choice of $\lambda$ and
$t$. Now, we suppose that $j$ is not in $\mathfrak{a}$, and we prove
that for a generic choice of $\lambda$ and $t$, $ac-b^2$ is non-zero.
The quantity $ac-b^2$ is a polynomial in the coefficients
$(\bu_i)_{i\in T_j}$, and $(t_i)_{i \in \{2,\dots,n\}}$, and we have
to show that it is not identically zero. We discuss two cases; in both
of them, we prove that a suitable specialization of $ac-b^2$ is
non-zero.

Suppose first that for at least one index $\sigma$ in $T_j$,
$Q_\sigma$ is not reduced. In this case, there exists as least one
index $\rho$ in $\{2,\dots,n\}$ such that
$P_{\sigma,\rho}(u_{\sigma,2},\dots,u_{\sigma,D_\sigma})$ is not
identically zero \todo{explain better}. Let us set all $\bu_{\sigma'}$
to $0$, for $\sigma'$ in $T_j-\{\sigma\}$, as well as $u_{\sigma,1}$,
and all $t_r$ for $r\ne \rho$. Then, under this specialization,
$ac-b^2$ becomes
$-(P_{\sigma,\rho}(u_{\sigma,2},\dots,u_{\sigma,D_\sigma})t_\rho)^2$,
which is non-zero, so that $ac-b^2$ itself must be non-zero.

Else, since $j$ is not in $\mathfrak{a}$, we can assume that $T_j$
has cardinality at least $2$, with $Q_\sigma$ reduced for all $\sigma$
in $T_j$ (so that $P_{\sigma,r}$ and $P_{\sigma,r,s}$ vanish for 
all such $\sigma$ and all $r,s$). Suppose that $\sigma$ and $\sigma'$ are two indices in
$T_j$; we set all indices $u_{\sigma'',1}$ to zero, for $\sigma''$
in $T_j-\{\sigma,\sigma'\}$. We are left with
$$
a=u_{\sigma,1}+u_{\sigma',1},\quad
b=u_{\sigma,1}t(\balpha_{\sigma})+u_{\sigma',1}t(\balpha_{\sigma'}),\quad
c=u_{\sigma,1}t(\balpha_{\sigma})^2+u_{\sigma',1}t(\balpha_{\sigma'})^2.
$$
Then, $ac-b^2$ is equal to $2u_{\sigma,1}u_{\sigma',1}(t(\balpha_{\sigma})-t(\balpha_{\sigma'}))^2$,
which is non-zero, since $\balpha_\sigma \ne \balpha_{\sigma'}$.
\end{proof}

The previous lemmas allow us to write Algorithm
$\mathsf{ParametrizationX}_1$. After computing $M$, we determine its
factor $P=\prod_{j \in \{1,\dots,c\}, m_j=1} (T-r_j)$. We split this
polynomial further using the previous results in order to find
$\prod_{j \in \mathfrak{a}} (T-r_j)$, and we conclude using the same
kind of calculations as in $\mathsf{ParametrizationGeneric}$.

\begin{algorithm}[H]
 \caption{$\mathsf{ParametrizationX}_1(\ell,t)$}
~\\
 {\bf Input:} \vspace{-0.5em}
 \begin{itemize}\setlength\itemsep{0em}
 \item a linear form $\ell$ over $Q$
 \item a linear form $t=t_2 X_2 + \cdots + t_n X_n$
 \end{itemize}
 {\bf Output:} polynomials $((P,V_1,\dots,V_n),X_1)$
 \begin{enumerate}\setlength\itemsep{0em}
 \item let $M$ be the minimal polynomial of the sequence $(\ell(X_1^s))_{s \ge 0}$ and let $\delta$ be its degree
 \item let $P = \prod_{r \text{~root of $M$ of multiplicity 1}}(T-r)$
 \item let $B=T^\delta M(1/T)$
 \item let $t$ be a random linear form in $X_2,\dots,X_n$
 \item \textbf{for} $i=0,1,2$ \textbf{do}
   \begin{enumerate}
   \item let $A_i = \big (\sum_{s < \delta} \ell(t^i X_1^s)T^s\big )B \mod T^{\delta}$
   \item let $\tilde A_i = T^{\delta -1}A_i(1/T)$
   \end{enumerate}
 \item\label{step:updateP} let $P = \gcd(P, \tilde A_0 \tilde A_2-\tilde A_1^2)$
 \item \textbf{for} $i=2,\dots,n$ \textbf{do}
   \begin{enumerate}
   \item let $A_{X_i} = \big (\sum_{s < \delta} \ell(X_2 X_1^s)T^s\big)B \mod T^{\delta}$ 
   \item let $\tilde A_{X_i} = T^{\delta -1}A_{X_i}(1/T)$
   \end{enumerate}
 \item \textbf{return} $((P,T,\tilde A_{X_2}/\tilde A_1 \bmod P, \dots,\tilde A_{X_n}/\tilde A_{1} \bmod P),X_1)$
 \end{enumerate}
\label{algo:para}
\end{algorithm}


\begin{Lemma}
  Suppose that $\ell$ is a generic element of ${\rm
    hom}_{\Kbar}(Q,\Kbar)$ and that $t$ is a generic linear form. Then
  the output $((P,V_1,\dots,V_n),X_1)$ of
  $\mathsf{ParametrizationX}_1(\ell,t)$ is a zero-dimensional
  parametrization of $V_{\mathfrak{A}}$.
\end{Lemma}
\begin{proof}
  Lemma~\ref{lemma:minpoly} shows that for a generic choice of $\ell$,
  $M$ is the minimal polynomial of $X_1$, so that we indeed have
  $P=\prod_{j \in \{1,\dots,c\}, m_j=1} (T-r_j)$. Let then $r_j$ be
  one of these roots; by Lemma~\ref{lemma:valuelambda}, for $i=0,1,2$
  we have $\tilde A_i(r_j) = M'(r_j) (t^i \cdot \lambda_j)(1)$, where
  $\lambda_j =\sum_{i \in T_j} \ell_i$, and the $\ell_i$'s are the
  components of $\ell$. 

  As a result, the value of $\tilde A_0 \tilde A_2 - \tilde A_1^2$ at
  $r_j$ is (up to the non-zero factor $M'(r_j)^2$) equal to the
  quantity $ac-b^2$ defined in Lemma~\ref{lemma:acb2}, so for a
  generic choice of $\ell$ and $t$, it vanishes if and only if $j$ is
  in $\mathfrak{a}$. Thus, after Step~\ref{step:updateP}, 
  $P$ is equal to $\prod_{j \in \mathfrak{a}} (T-r_j)$.

  The last step is to compute the zero-dimensional parametrization of
  $V_{\mathfrak{A}}$. This is done using again
  Lemma~\ref{lemma:valuelambda}. Indeed, for $j$ in $\mathfrak{a}$, 
  $T_j$ is simply equal to $\{\sigma_j\}$, so that we have, for $i=2,\dots,n$,
  $$\tilde A_1(r_j)=M'(r_j) \lambda_j(1) \quad\text{and}\quad \tilde
  A_{X_i}(r_j) = M'(r_j) (X_i \cdot \lambda_j)(1) = M'(r_j) \lambda_j(X_i).$$ Now, since $j$
  is in $\mathfrak{a}$, $Q_{\sigma_j}$ is reduced, so that there
  exists a constant $\lambda_{j,1}$ such that for all $f$ in
  $\Kbar[X_1,\dots,X_n]$, $\lambda_j(f)$ takes the form $\lambda_{j,1}
  f(\balpha_{\sigma_j})$. This shows that, as claimed,
  $$\frac{\tilde A_{X_j}(r_j)}{\tilde A_1 (r_j)} = \frac
  {M'(r_j) \lambda_{j,1} \alpha_{j,i}}{M'(r_j) \lambda_{j,1}} = \alpha_{j,i}.$$
  For $i=1$, since we use $X_1$ as a separating variable for $V_{\mathfrak{A}}$, 
  we simply add the polynomial $T$ to our list.
\end{proof}


\bibliographystyle{plain}
\bibliography{all}

\end{document}




